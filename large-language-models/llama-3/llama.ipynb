{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 2 vs Llama 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/miniconda3/envs/zaai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /Users/rafael/Documents/lab/large-language-models/llama-3/model/nous-hermes-llama-2-7b.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1024\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =     0.16 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     1.50 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'LLaMA v2'}\n",
      "Using fallback chat format: None\n",
      "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from /Users/rafael/Documents/lab/large-language-models/llama-3/model/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = ..\n",
      "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,128256]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 256/128256 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = ..\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4685.30 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1024\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   128.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =     0.16 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     4.04 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\", 'tokenizer.ggml.eos_token_id': '128009', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.model': 'gpt2', 'llama.attention.head_count_kv': '8', 'llama.context_length': '8192', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '500000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.block_count': '32', 'llama.embedding_length': '4096', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': '..', 'llama.vocab_size': '128256'}\n",
      "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from generator.generator import Generator\n",
    "from datasets import load_dataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "llama2 = Generator(model='llama2')\n",
    "llama3 = Generator(model='llama3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Q&A Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\", split=\"train\")\n",
    "squad = squad.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary to save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama2_metrics = {\n",
    "    \"words_per_second\": [],\n",
    "    \"words\": [],\n",
    "}\n",
    "\n",
    "llama3_metrics = {\n",
    "    \"words_per_second\": [],\n",
    "    \"words\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     1 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  102337.42 ms /   463 tokens (  221.03 ms per token,     4.52 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  102559.97 ms /   464 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =    1026.29 ms /   639 runs   (    1.61 ms per token,   622.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  141897.93 ms /   366 tokens (  387.70 ms per token,     2.58 tokens per second)\n",
      "llama_print_timings:        eval time =  250747.35 ms /   638 runs   (  393.02 ms per token,     2.54 tokens per second)\n",
      "llama_print_timings:       total time =  406870.71 ms /  1004 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      16.25 ms /    34 runs   (    0.48 ms per token,  2092.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   75134.89 ms /   288 tokens (  260.89 ms per token,     3.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12137.77 ms /    33 runs   (  367.81 ms per token,     2.72 tokens per second)\n",
      "llama_print_timings:       total time =   87632.81 ms /   321 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     144.38 ms /    63 runs   (    2.29 ms per token,   436.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   70334.23 ms /   235 tokens (  299.29 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:        eval time =   25669.28 ms /    62 runs   (  414.02 ms per token,     2.42 tokens per second)\n",
      "llama_print_timings:       total time =   97938.96 ms /   297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    17 runs   (    0.49 ms per token,  2036.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   96227.13 ms /   381 tokens (  252.56 ms per token,     3.96 tokens per second)\n",
      "llama_print_timings:        eval time =    7565.85 ms /    16 runs   (  472.87 ms per token,     2.11 tokens per second)\n",
      "llama_print_timings:       total time =  104116.10 ms /   397 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =    1239.15 ms /   713 runs   (    1.74 ms per token,   575.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  112526.19 ms /   292 tokens (  385.36 ms per token,     2.59 tokens per second)\n",
      "llama_print_timings:        eval time =  291451.50 ms /   712 runs   (  409.34 ms per token,     2.44 tokens per second)\n",
      "llama_print_timings:       total time =  421552.96 ms /  1004 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1675.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   60208.60 ms /   223 tokens (  269.99 ms per token,     3.70 tokens per second)\n",
      "llama_print_timings:        eval time =    2255.22 ms /     6 runs   (  375.87 ms per token,     2.66 tokens per second)\n",
      "llama_print_timings:       total time =   62662.78 ms /   229 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =    1339.48 ms /   804 runs   (    1.67 ms per token,   600.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   63224.97 ms /   200 tokens (  316.12 ms per token,     3.16 tokens per second)\n",
      "llama_print_timings:        eval time =  330655.45 ms /   804 runs   (  411.26 ms per token,     2.43 tokens per second)\n",
      "llama_print_timings:       total time =  412075.75 ms /  1004 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      17.32 ms /    28 runs   (    0.62 ms per token,  1617.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   50160.60 ms /   139 tokens (  360.87 ms per token,     2.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10166.44 ms /    27 runs   (  376.53 ms per token,     2.66 tokens per second)\n",
      "llama_print_timings:       total time =   60607.60 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     125.34 ms /    60 runs   (    2.09 ms per token,   478.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   49580.43 ms /   120 tokens (  413.17 ms per token,     2.42 tokens per second)\n",
      "llama_print_timings:        eval time =   24798.42 ms /    59 runs   (  420.31 ms per token,     2.38 tokens per second)\n",
      "llama_print_timings:       total time =   76007.12 ms /   179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /     4 runs   (    0.49 ms per token,  2043.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   75162.18 ms /   299 tokens (  251.38 ms per token,     3.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1040.25 ms /     3 runs   (  346.75 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =   76436.06 ms /   302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     138.38 ms /    87 runs   (    1.59 ms per token,   628.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   73042.71 ms /   253 tokens (  288.71 ms per token,     3.46 tokens per second)\n",
      "llama_print_timings:        eval time =   31021.53 ms /    86 runs   (  360.72 ms per token,     2.77 tokens per second)\n",
      "llama_print_timings:       total time =  106460.46 ms /   339 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2079.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   62921.95 ms /   253 tokens (  248.70 ms per token,     4.02 tokens per second)\n",
      "llama_print_timings:        eval time =     280.27 ms /     1 runs   (  280.27 ms per token,     3.57 tokens per second)\n",
      "llama_print_timings:       total time =   63403.35 ms /   254 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      50.09 ms /    32 runs   (    1.57 ms per token,   638.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   60858.17 ms /   214 tokens (  284.38 ms per token,     3.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10840.11 ms /    31 runs   (  349.68 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =   72792.26 ms /   245 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    19 runs   (    0.44 ms per token,  2282.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37759.67 ms /   147 tokens (  256.87 ms per token,     3.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5959.98 ms /    18 runs   (  331.11 ms per token,     3.02 tokens per second)\n",
      "llama_print_timings:       total time =   43972.19 ms /   165 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      26.14 ms /    16 runs   (    1.63 ms per token,   612.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   30651.36 ms /   118 tokens (  259.76 ms per token,     3.85 tokens per second)\n",
      "llama_print_timings:        eval time =    5375.40 ms /    15 runs   (  358.36 ms per token,     2.79 tokens per second)\n",
      "llama_print_timings:       total time =   36793.34 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    22 runs   (    0.59 ms per token,  1702.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   40277.50 ms /   215 tokens (  187.34 ms per token,     5.34 tokens per second)\n",
      "llama_print_timings:        eval time =    7150.58 ms /    21 runs   (  340.50 ms per token,     2.94 tokens per second)\n",
      "llama_print_timings:       total time =   47734.41 ms /   236 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =    1769.73 ms /   816 runs   (    2.17 ms per token,   461.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   42949.90 ms /   189 tokens (  227.25 ms per token,     4.40 tokens per second)\n",
      "llama_print_timings:        eval time =  360334.88 ms /   815 runs   (  442.13 ms per token,     2.26 tokens per second)\n",
      "llama_print_timings:       total time =  424285.26 ms /  1004 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     1 runs   (    0.97 ms per token,  1031.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   84638.17 ms /   279 tokens (  303.36 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   84854.36 ms /   280 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =    1680.54 ms /   771 runs   (    2.18 ms per token,   458.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   84364.63 ms /   234 tokens (  360.53 ms per token,     2.77 tokens per second)\n",
      "llama_print_timings:        eval time =  324813.05 ms /   770 runs   (  421.84 ms per token,     2.37 tokens per second)\n",
      "llama_print_timings:       total time =  428177.64 ms /  1004 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    12 runs   (    0.67 ms per token,  1486.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   48562.49 ms /   163 tokens (  297.93 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:        eval time =    4211.88 ms /    11 runs   (  382.90 ms per token,     2.61 tokens per second)\n",
      "llama_print_timings:       total time =   52990.05 ms /   174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      61.14 ms /    36 runs   (    1.70 ms per token,   588.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   48558.55 ms /   133 tokens (  365.10 ms per token,     2.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14869.33 ms /    35 runs   (  424.84 ms per token,     2.35 tokens per second)\n",
      "llama_print_timings:       total time =   64616.81 ms /   168 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    18 runs   (    0.54 ms per token,  1840.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   82104.02 ms /   339 tokens (  242.19 ms per token,     4.13 tokens per second)\n",
      "llama_print_timings:        eval time =    6614.77 ms /    17 runs   (  389.10 ms per token,     2.57 tokens per second)\n",
      "llama_print_timings:       total time =   89111.37 ms /   356 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      46.90 ms /    27 runs   (    1.74 ms per token,   575.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   79233.54 ms /   299 tokens (  265.00 ms per token,     3.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12457.08 ms /    26 runs   (  479.12 ms per token,     2.09 tokens per second)\n",
      "llama_print_timings:       total time =   93211.14 ms /   325 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    21 runs   (    0.65 ms per token,  1545.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   41659.86 ms /   136 tokens (  306.32 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:        eval time =    6744.81 ms /    20 runs   (  337.24 ms per token,     2.97 tokens per second)\n",
      "llama_print_timings:       total time =   48727.86 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     129.57 ms /    63 runs   (    2.06 ms per token,   486.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26912.31 ms /   107 tokens (  251.52 ms per token,     3.98 tokens per second)\n",
      "llama_print_timings:        eval time =   25037.80 ms /    62 runs   (  403.84 ms per token,     2.48 tokens per second)\n",
      "llama_print_timings:       total time =   53802.47 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =     102.81 ms /   222 runs   (    0.46 ms per token,  2159.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   63585.61 ms /   163 tokens (  390.10 ms per token,     2.56 tokens per second)\n",
      "llama_print_timings:        eval time =   82651.50 ms /   221 runs   (  373.99 ms per token,     2.67 tokens per second)\n",
      "llama_print_timings:       total time =  147959.12 ms /   384 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     252.19 ms /   135 runs   (    1.87 ms per token,   535.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   84071.02 ms /   130 tokens (  646.70 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:        eval time =   88159.17 ms /   134 runs   (  657.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =  176262.50 ms /   264 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /     7 runs   (    0.92 ms per token,  1089.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   81870.38 ms /   246 tokens (  332.81 ms per token,     3.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2746.51 ms /     6 runs   (  457.75 ms per token,     2.18 tokens per second)\n",
      "llama_print_timings:       total time =   84879.50 ms /   252 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     128.24 ms /    80 runs   (    1.60 ms per token,   623.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   60467.05 ms /   203 tokens (  297.87 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:        eval time =   29101.59 ms /    79 runs   (  368.37 ms per token,     2.71 tokens per second)\n",
      "llama_print_timings:       total time =   91789.21 ms /   282 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      10.91 ms /    19 runs   (    0.57 ms per token,  1741.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   60847.80 ms /   243 tokens (  250.40 ms per token,     3.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5881.33 ms /    18 runs   (  326.74 ms per token,     3.06 tokens per second)\n",
      "llama_print_timings:       total time =   67017.87 ms /   261 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     144.94 ms /    64 runs   (    2.26 ms per token,   441.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   59599.28 ms /   212 tokens (  281.13 ms per token,     3.56 tokens per second)\n",
      "llama_print_timings:        eval time =   25207.13 ms /    63 runs   (  400.11 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =   86816.11 ms /   275 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /     1 runs   (    2.39 ms per token,   418.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   62666.18 ms /   168 tokens (  373.01 ms per token,     2.68 tokens per second)\n",
      "llama_print_timings:        eval time =    3961.10 ms /     1 runs   ( 3961.10 ms per token,     0.25 tokens per second)\n",
      "llama_print_timings:       total time =   66805.08 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =    1854.15 ms /   857 runs   (    2.16 ms per token,   462.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   67988.49 ms /   148 tokens (  459.38 ms per token,     2.18 tokens per second)\n",
      "llama_print_timings:        eval time =  347703.89 ms /   856 runs   (  406.20 ms per token,     2.46 tokens per second)\n",
      "llama_print_timings:       total time =  438626.48 ms /  1004 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    11 runs   (    0.61 ms per token,  1630.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   58714.09 ms /   196 tokens (  299.56 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:        eval time =    3858.53 ms /    10 runs   (  385.85 ms per token,     2.59 tokens per second)\n",
      "llama_print_timings:       total time =   62827.10 ms /   206 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      89.61 ms /    48 runs   (    1.87 ms per token,   535.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   50815.40 ms /   157 tokens (  323.66 ms per token,     3.09 tokens per second)\n",
      "llama_print_timings:        eval time =   19940.08 ms /    47 runs   (  424.26 ms per token,     2.36 tokens per second)\n",
      "llama_print_timings:       total time =   72269.49 ms /   204 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /     2 runs   (    0.68 ms per token,  1470.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   45893.05 ms /   157 tokens (  292.31 ms per token,     3.42 tokens per second)\n",
      "llama_print_timings:        eval time =     309.05 ms /     1 runs   (  309.05 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =   46340.08 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     169.35 ms /    78 runs   (    2.17 ms per token,   460.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   42038.06 ms /   143 tokens (  293.97 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:        eval time =   30686.29 ms /    77 runs   (  398.52 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =   75008.22 ms /   220 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     1 runs   (    0.47 ms per token,  2145.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   61348.96 ms /   235 tokens (  261.06 ms per token,     3.83 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   61529.28 ms /   236 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      37.28 ms /    23 runs   (    1.62 ms per token,   616.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   57976.31 ms /   197 tokens (  294.30 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11690.16 ms /    22 runs   (  531.37 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =   70729.27 ms /   219 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      19.16 ms /    39 runs   (    0.49 ms per token,  2035.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   71887.31 ms /   231 tokens (  311.20 ms per token,     3.21 tokens per second)\n",
      "llama_print_timings:        eval time =   14093.24 ms /    38 runs   (  370.87 ms per token,     2.70 tokens per second)\n",
      "llama_print_timings:       total time =   86465.62 ms /   269 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      16.70 ms /     9 runs   (    1.86 ms per token,   538.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   65646.38 ms /   186 tokens (  352.94 ms per token,     2.83 tokens per second)\n",
      "llama_print_timings:        eval time =    3017.14 ms /     8 runs   (  377.14 ms per token,     2.65 tokens per second)\n",
      "llama_print_timings:       total time =   69412.67 ms /   194 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      13.56 ms /    30 runs   (    0.45 ms per token,  2211.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   77017.88 ms /   298 tokens (  258.45 ms per token,     3.87 tokens per second)\n",
      "llama_print_timings:        eval time =   10302.66 ms /    29 runs   (  355.26 ms per token,     2.81 tokens per second)\n",
      "llama_print_timings:       total time =   87956.34 ms /   327 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =    1247.42 ms /   752 runs   (    1.66 ms per token,   602.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   71788.75 ms /   253 tokens (  283.75 ms per token,     3.52 tokens per second)\n",
      "llama_print_timings:        eval time =  311220.56 ms /   751 runs   (  414.41 ms per token,     2.41 tokens per second)\n",
      "llama_print_timings:       total time =  402532.06 ms /  1004 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      27.88 ms /    61 runs   (    0.46 ms per token,  2187.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   71277.85 ms /   253 tokens (  281.73 ms per token,     3.55 tokens per second)\n",
      "llama_print_timings:        eval time =   20529.92 ms /    60 runs   (  342.17 ms per token,     2.92 tokens per second)\n",
      "llama_print_timings:       total time =   92431.63 ms /   313 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     113.22 ms /    64 runs   (    1.77 ms per token,   565.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   79221.21 ms /   221 tokens (  358.47 ms per token,     2.79 tokens per second)\n",
      "llama_print_timings:        eval time =   29557.40 ms /    63 runs   (  469.17 ms per token,     2.13 tokens per second)\n",
      "llama_print_timings:       total time =  111029.97 ms /   284 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      18.25 ms /    28 runs   (    0.65 ms per token,  1533.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   53568.69 ms /   188 tokens (  284.94 ms per token,     3.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10998.12 ms /    27 runs   (  407.34 ms per token,     2.45 tokens per second)\n",
      "llama_print_timings:       total time =   64974.21 ms /   215 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      44.98 ms /    19 runs   (    2.37 ms per token,   422.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   51908.76 ms /   155 tokens (  334.90 ms per token,     2.99 tokens per second)\n",
      "llama_print_timings:        eval time =    6650.33 ms /    18 runs   (  369.46 ms per token,     2.71 tokens per second)\n",
      "llama_print_timings:       total time =   59575.21 ms /   173 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1902.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   59463.49 ms /   251 tokens (  236.91 ms per token,     4.22 tokens per second)\n",
      "llama_print_timings:        eval time =    2200.27 ms /     6 runs   (  366.71 ms per token,     2.73 tokens per second)\n",
      "llama_print_timings:       total time =   61923.99 ms /   257 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     104.24 ms /    57 runs   (    1.83 ms per token,   546.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   61583.14 ms /   216 tokens (  285.11 ms per token,     3.51 tokens per second)\n",
      "llama_print_timings:        eval time =   23370.19 ms /    57 runs   (  410.00 ms per token,     2.44 tokens per second)\n",
      "llama_print_timings:       total time =   86872.17 ms /   273 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     1 runs   (    0.45 ms per token,  2207.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   36014.90 ms /    95 tokens (  379.10 ms per token,     2.64 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   36102.81 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     185.91 ms /   107 runs   (    1.74 ms per token,   575.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   29133.29 ms /    85 tokens (  342.74 ms per token,     2.92 tokens per second)\n",
      "llama_print_timings:        eval time =   42560.65 ms /   106 runs   (  401.52 ms per token,     2.49 tokens per second)\n",
      "llama_print_timings:       total time =   74670.42 ms /   191 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     1 runs   (    0.63 ms per token,  1584.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   51050.26 ms /   216 tokens (  236.34 ms per token,     4.23 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   51219.69 ms /   217 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =     131.88 ms /    60 runs   (    2.20 ms per token,   454.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   44110.72 ms /   179 tokens (  246.43 ms per token,     4.06 tokens per second)\n",
      "llama_print_timings:        eval time =   27627.30 ms /    59 runs   (  468.26 ms per token,     2.14 tokens per second)\n",
      "llama_print_timings:       total time =   73779.52 ms /   238 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      21.47 ms /    33 runs   (    0.65 ms per token,  1536.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   42916.70 ms /   157 tokens (  273.35 ms per token,     3.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10566.59 ms /    32 runs   (  330.21 ms per token,     3.03 tokens per second)\n",
      "llama_print_timings:       total time =   54069.27 ms /   189 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      46.02 ms /    24 runs   (    1.92 ms per token,   521.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   48547.89 ms /   120 tokens (  404.57 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:        eval time =   10582.89 ms /    24 runs   (  440.95 ms per token,     2.27 tokens per second)\n",
      "llama_print_timings:       total time =   60118.00 ms /   144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /     6 runs   (    0.66 ms per token,  1516.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   53886.87 ms /   184 tokens (  292.86 ms per token,     3.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1823.11 ms /     6 runs   (  303.85 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =   55888.74 ms /   190 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =      81.22 ms /    43 runs   (    1.89 ms per token,   529.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   70481.54 ms /   163 tokens (  432.40 ms per token,     2.31 tokens per second)\n",
      "llama_print_timings:        eval time =   17547.11 ms /    42 runs   (  417.79 ms per token,     2.39 tokens per second)\n",
      "llama_print_timings:       total time =   89682.37 ms /   205 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   16375.34 ms\n",
      "llama_print_timings:      sample time =      48.25 ms /    75 runs   (    0.64 ms per token,  1554.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   60885.26 ms /   212 tokens (  287.19 ms per token,     3.48 tokens per second)\n",
      "llama_print_timings:        eval time =   30488.79 ms /    74 runs   (  412.01 ms per token,     2.43 tokens per second)\n",
      "llama_print_timings:       total time =   92198.38 ms /   286 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4174.89 ms\n",
      "llama_print_timings:      sample time =    1959.53 ms /   827 runs   (    2.37 ms per token,   422.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   63668.24 ms /   178 tokens (  357.69 ms per token,     2.80 tokens per second)\n",
      "llama_print_timings:        eval time =  350486.56 ms /   826 runs   (  424.32 ms per token,     2.36 tokens per second)\n",
      "llama_print_timings:       total time =  437352.61 ms /  1004 tokens\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    context = squad[i]['context']\n",
    "    query = squad[i]['question']\n",
    "    answer = squad[i]['answers']['text'][0]\n",
    "\n",
    "    # llama 2\n",
    "    answer_llama2, words_per_second, words = utils.get_llm_response(llama2, context, query)\n",
    "    llama2_metrics[\"words_per_second\"].append(words_per_second)\n",
    "    llama2_metrics[\"words\"].append(words)\n",
    "\n",
    "    # llama 3\n",
    "    answer_llama3, words_per_second, words = utils.get_llm_response(llama3, context, query)\n",
    "    llama3_metrics[\"words_per_second\"].append(words_per_second)\n",
    "    llama3_metrics[\"words\"].append(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Llama 2 7B vs Llama 3 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama2_metrics = pd.DataFrame(llama2_metrics)\n",
    "llama2_metrics['model'] = 'Llama 2 7B'\n",
    "llama3_metrics = pd.DataFrame(llama3_metrics)\n",
    "llama3_metrics['model'] = 'Llama 3 8B'\n",
    "\n",
    "# create single data frame for plotting\n",
    "metrics = pd.concat([llama2_metrics, llama3_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle('Llama 2 7B vs Llama 3 8B')\n",
    "\n",
    "sns.barplot(ax=axes[0], data=metrics, y='words_per_second', x='model', hue='model', palette=[\"#070620\", \"#dd4fe4\"])\n",
    "axes[0].set_title(\"Words per second\")\n",
    "\n",
    "sns.barplot(ax=axes[1], data=metrics, y='words', x='model', hue='model', palette=[\"#070620\", \"#dd4fe4\"])\n",
    "axes[1].set_title(\"Avg Answer length\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zaai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
